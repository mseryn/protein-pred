{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neilgetty/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from itertools import islice, product\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Data Preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window(seq, k=3):\n",
    "    \"\"\" \n",
    "    Generate generate all kmers for a sequence\n",
    "    Params:\n",
    "        seq....dna sequence\n",
    "        k......length of kmer\n",
    "    \"\"\"\n",
    "    it = iter(seq)\n",
    "    result = tuple(islice(it, k))\n",
    "    if len(result) == k:\n",
    "        yield result\n",
    "    for elem in it:\n",
    "        result = result[1:] + (elem,)\n",
    "        yield result\n",
    "\n",
    "\n",
    "def reverse_complement(kmer):\n",
    "    \"\"\"\n",
    "    Generate a kmers complement\n",
    "    Params:\n",
    "        kmer....The kmer to generate the complement for\n",
    "    \"\"\"\n",
    "    comp = {'a': 't', 'c': 'g', 't': 'a', 'g': 'c'}\n",
    "    rc = ()\n",
    "    for x in range(len(kmer)):\n",
    "        rc = rc + (comp[kmer[len(kmer)-x-1]],)\n",
    "    return rc\n",
    "\n",
    "\n",
    "def gen_vocab(k=3):\n",
    "    \"\"\"\n",
    "    Generate index kmer pairs for all possible kmers, binning complements together\n",
    "    Params:\n",
    "        k....length of kmer\n",
    "    \"\"\"\n",
    "    all_kmers = list(product('atcg', repeat=k))\n",
    "    vocab = {}\n",
    "    for mer in all_kmers:\n",
    "        rc = reverse_complement(mer)\n",
    "        if rc in vocab:\n",
    "            vocab[mer] = vocab[rc]\n",
    "        else:\n",
    "            vocab[mer] = len(vocab)\n",
    "    return vocab\n",
    "\n",
    "\n",
    "def convert_labels(labels):\n",
    "    \"\"\" \n",
    "    Convert labels to indexes\n",
    "    Params:\n",
    "        labels...Original k class string labels\n",
    "    \"\"\"\n",
    "    label_idxs = {}\n",
    "    new_labels = np.empty(len(labels))\n",
    "    for x in range(len(labels)):\n",
    "        new_labels[x] = label_idxs.setdefault(labels[x], len(label_idxs))\n",
    "    return new_labels\n",
    "\n",
    "\n",
    "def featurize_data(file, k=3):\n",
    "    \"\"\" \n",
    "    Featurize sequences and index labels\n",
    "    Params:\n",
    "        file....Delimited data file\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(file, names=[\"label\", \"dna\"], usecols=[0,7], delimiter = '\\t')\n",
    "    labels = convert_labels(data.label)\n",
    "    #labels = data.label\n",
    "    kmers = [Counter(list(window(x, k))) for x in data.dna]\n",
    "    vocab = gen_vocab(k)\n",
    "\n",
    "    features = np.zeros((len(data.label), len(vocab)))\n",
    "    for row in range (len(features)):\n",
    "        for kmer in kmers[row].keys():\n",
    "            features[row][vocab[kmer]] = kmers[row][kmer]\n",
    "\n",
    "    return labels, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Cross validation and Test/train split functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_accuracy(clf, X, labels, split):\n",
    "    \"\"\" \n",
    "    Compute the average testing accuracy over k folds of cross-validation. \n",
    "    Params:\n",
    "        clf......A classifier.\n",
    "        X........A matrix of features.\n",
    "        labels...The true labels for each instance in X\n",
    "        split........The fold indices\n",
    "    Returns:\n",
    "        The average testing accuracy of the classifier\n",
    "        over each fold of cross-validation.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for train_index, test_index in split:\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        scores.append(accuracy_score(y_test, clf.predict(X_test)))\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "def test_train_split(clf, split):\n",
    "    \"\"\"\n",
    "    Compute the accuracy of a train/test split\n",
    "    Params:\n",
    "        clf......A classifier.\n",
    "        split....indices\n",
    "    Returns:\n",
    "        The testing accuracy and the confusion\n",
    "        matrix.\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = split\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    return score, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Fit and score each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_all(labels, features, clfs, folds, model_names):\n",
    "    \"\"\" \n",
    "    Compute the average testing accuracy over k folds of cross-validation. \n",
    "    Params:\n",
    "        labels.......The true labels for each instance in X\n",
    "        features.....The feature vectors for each instance\n",
    "        clfs.........The classifiers to fit and test\n",
    "        folds........Number of folds for cross validation\n",
    "        model_names..Readable names of each classifier\n",
    "    Returns:\n",
    "        A dataframe with each models results\n",
    "    \"\"\"\n",
    "    tts_split = train_test_split(\n",
    "        features, labels, test_size=0.2, random_state=0)\n",
    "\n",
    "    cv_split = KFold(len(labels), n_folds=folds, shuffle=True)\n",
    "\n",
    "    results = pd.DataFrame(columns=[\"Model\", \"CV Score\", \"Test Score\", \"Time\"])\n",
    "\n",
    "    for x in range(len(clfs)):\n",
    "        start = time.time()\n",
    "        clf = clfs[x]\n",
    "        cv_score = cross_validation_accuracy(clf, features, labels, cv_split)\n",
    "        tts_score, cm = test_train_split(clf, tts_split)\n",
    "        end = time.time()\n",
    "        elapsed = end-start\n",
    "        results.loc[results.shape[0]] = ([model_names[x], cv_score, tts_score, elapsed])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Declare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    file = \"data/ref.100ec.pgf.seqs.filter\"\n",
    "    k = 3\n",
    "    labels, features = featurize_data(file, k)\n",
    "    folds = 5\n",
    "    clfs = [SVC(), MultinomialNB(), LogisticRegression(), RandomForestClassifier(n_jobs=2), AdaBoostClassifier(n_estimators=10)]\n",
    "    model_names = [\"SVC\", \"Naive bayes\", \"Logistic Regression\", \"Random Forest\", \"AdaBoost\"]\n",
    "\n",
    "    print classify_all(labels, features, clfs, folds, model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  CV Score  Test Score        Time\n0                  SVC  0.193299    0.188698  207.802181\n1          Naive bayes  0.076903    0.071981    0.123263\n2  Logistic Regression  0.288435    0.301043  147.581321\n3        Random Forest  0.358339    0.352842    3.099816\n4             AdaBoost  0.053085    0.054827    2.935549\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}